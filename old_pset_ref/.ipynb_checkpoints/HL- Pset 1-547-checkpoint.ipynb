{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26dc0ed-46e5-4a6a-b7f2-d32dd92b93f3",
   "metadata": {},
   "source": [
    "# Hongfan Lu - Pset 1 - Youtube, BlueSky Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8f03973d-d870-431c-ab57-28cc5fa05bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd24a3-73c1-4c40-be40-c46f332f2b0f",
   "metadata": {},
   "source": [
    "### Q1 (10 pts): Keyword selection\n",
    "\n",
    "- Economy: We have record level high inflations and new threats of trade conflicts.\n",
    "- Trump: Donald Trump and whether he will be the republican candidate again will be a major concerns for both parties\n",
    "- Foreign Policy: With the Gaza-Isreali conflicts and the Russian-Ukrain war, the US foreign policy will be a major concern for US voters\n",
    "- Democracy: With Cambridge Analytics scandal and the Jan 6th riot, many people are concerned that the US democracy is at risk.\n",
    "- China: US voters will want to know the China policy that both democratic and the republican candidates might have.\n",
    "- Climate: climate issue has always been the heated topic between left and right.\n",
    "- Equality: Black Lives Matter movement and a series of social events has triggered voters' attention on equality in this new age.\n",
    "- Biden: Like Trump, Biden's name will also appear a lot since he is so far the face and soul of the democrat party\n",
    "- Democrat: left party\n",
    "- Republican: right party."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec06447-920c-402e-98b6-fe9684564e5d",
   "metadata": {},
   "source": [
    "### Q2) YouTube data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf04d3-298f-48eb-9ce5-6dead242913d",
   "metadata": {},
   "source": [
    "#### 2a (15 pts): For each of the two YouTube channels (CNN and FoxNews) use the YouTube API to list all the videos uploaded on the channel starting with the most recent. Then go over the videos and check whether the video title contains any of the election-related keywords you selected. If it does save relevant information about the video. Make sure that you have identified at least 50 election-related videos (according to your keywords) per channel, i.e., 100 videos in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "35e6725e-fcc6-43ae-a9a6-b3f4f783260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-api-python-client --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1637db0a-9e80-4bc5-a9fc-433a45a45439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube Key\n",
    "API_KEY = \"AIzaSyAFkh7VXLquY7VOKsKm2mJ_7RHM7n_PxwQ\"\n",
    "# keyword list\n",
    "keyword_list = ['Economy', \"Trump\", \"Foreign Policy\", \"Democracy\", \"China\", \"Climate\", \"Equality\", \"Biden\", \"Democrat\", \"Republican\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d0f7a47-abd8-49b3-92ac-5ee76babeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import json\n",
    "import googleapiclient\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7a1be153-7e11-4867-9106-ab76b9205a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Youtube API\n",
    "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "81271772-873f-4d8c-98ef-fff722af9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a847b1-040c-496a-a091-ab5bea14e5a5",
   "metadata": {},
   "source": [
    "#### To solve the issue that same word might have different forms; I will use stemming to reduce words to their basic form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ba56be0b-430f-433c-be53-9b18a4ad68f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hongfanlu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initialize NLTK\n",
    "nltk.download(\"punkt\")\n",
    "porter = PorterStemmer()\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "def11acb-3868-4729-85f4-f3148b333dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keyword_videos(keyword_list, channel_name):\n",
    "    relevant_videos = []\n",
    "    next_page_token = None\n",
    "    while len(relevant_videos) < 50:\n",
    "        request = youtube.search().list(\n",
    "            part='snippet, id',\n",
    "            q= channel_name,\n",
    "            maxResults=50,\n",
    "            pageToken=next_page_token,\n",
    "            order='date'\n",
    "        )\n",
    "        response = request.execute()  \n",
    "        stemmed_keywords = set(porter.stem(keyword) for keyword in keyword_list)\n",
    "        \n",
    "        for item in response.get('items', []):\n",
    "            video_title = item['snippet']['title'].lower()\n",
    "            if any(re.search(r'\\b{}\\b'.format(re.escape(porter.stem(keyword))), video_title) for keyword in stemmed_keywords):\n",
    "                video_id = item['id']['videoId']\n",
    "                # this is for viewCount\n",
    "                view_count = youtube.videos().list(\n",
    "                id = video_id,\n",
    "                part = 'statistics'\n",
    "                ).execute()\n",
    "                \n",
    "                video_info = {\n",
    "                    'Channel Name': channel_name,\n",
    "                    'Video ID':video_id,\n",
    "                    'Video title': item['snippet']['title'],\n",
    "                    'Video creation time': item['snippet']['publishedAt'],\n",
    "                    'Video number of views': view_count['items'][0]['statistics']['viewCount']       \n",
    "                }\n",
    "                relevant_videos.append(video_info)\n",
    "            if len(relevant_videos) >= 50:\n",
    "                break\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    print(f\"Found {len(relevant_videos)} keyword-related videos from {channel_name}.\")\n",
    "    return relevant_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "83f9d4f2-6897-4042-9365-70d3a4ca61ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 keyword-related videos from CNN.\n",
      "Found 50 keyword-related videos from FoxNews.\n"
     ]
    }
   ],
   "source": [
    "cnn_keyword_videoids = search_keyword_videos(keyword_list, \"CNN\")\n",
    "foxnews_keyword_videoids = search_keyword_videos(keyword_list, \"FoxNews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9598fb74-8c96-49ce-ab71-dce26c913096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all video ids from the list of libraries return from search_keyword_videos function\n",
    "\n",
    "cnn_videoids = [d['Video ID'] for d in cnn_keyword_videoids if 'Video ID' in d]\n",
    "fox_videoids = [d['Video ID'] for d in foxnews_keyword_videoids if 'Video ID' in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e1027-64b5-43d0-a518-14f06655a8e5",
   "metadata": {},
   "source": [
    "#### 2b (15 pts): For each video fetch the 30 most relevant (as sorted by the API) comments. If the video has less than 30 comments, extract as many comments as there are. Make sure that this does not happen very often; if it does, understand why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "26f58dd0-4b03-4e4b-8696-c984c061b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "def extract_30_comments(video_id_list): \n",
    "    comments_per_video = []\n",
    "    for vid in video_id_list:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                videoId = vid,\n",
    "                part = \"id,snippet,replies\",\n",
    "                textFormat = \"plainText\",\n",
    "                order = \"time\",\n",
    "                maxResults = 30\n",
    "            )\n",
    "            response = request.execute()\n",
    "            \n",
    "            for item in response[\"items\"]:\n",
    "                comments = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                has_reply = item[\"snippet\"][\"totalReplyCount\"]\n",
    "                if has_reply != 0:\n",
    "                    replies = []\n",
    "                    for i in range(len(item[\"replies\"][\"comments\"])):\n",
    "                        reply = item[\"replies\"][\"comments\"][i]['snippet'][\"textDisplay\"]\n",
    "                        replies.append(reply)\n",
    "                else:\n",
    "                    replies = None\n",
    "                comment_info = {\n",
    "                    'Video ID': vid,\n",
    "                    'Comment id': item['snippet']['topLevelComment']['id'],\n",
    "                    'Comment title': item['snippet']['topLevelComment']['snippet']['textOriginal'],\n",
    "                    'Comment creation time': item['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                    'Comment number of likes': item['snippet']['topLevelComment']['snippet']['likeCount'],\n",
    "                    'Comment content': comments,\n",
    "                    'Replies': replies\n",
    "                }\n",
    "                comments_per_video.append(comment_info)\n",
    "        except HttpError as e:\n",
    "            if e.resp.status == 403:\n",
    "                print(f\"Comments are disabled for video with ID: {vid}\")\n",
    "                comments_per_video.append(f\"Comments are disabled for video with ID: {vid}\")\n",
    "            else:\n",
    "                raise e  # Re-raise the exception if it's not a 403 error\n",
    "    return comments_per_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d712a25a-0e22-420f-8ceb-b88751198a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_videos_comments = extract_30_comments(cnn_videoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "60526594-9517-4a51-9790-090483429997",
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_videos_comments = extract_30_comments(fox_videoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61526c5-c73b-414d-8022-935f0d0c1434",
   "metadata": {},
   "source": [
    "#### 2c (8 pts): Create a Pandas data frame that contains the relevant information about the data you extracted. Each row of your data frame should represent one comment. It should, at least, include the following columns (you can name the columns as you like):\n",
    "- Channel name\n",
    "- Video id\n",
    "- Video title\n",
    "- Video creation time\n",
    "- Video number of views\n",
    "- Comment id\n",
    "- Comment title\n",
    "- Comment creation time\n",
    "- Comment number of likes\n",
    "\n",
    "Include any other information that you think might be relevant for further analyses. The next two assignments will build on this one and you will be asked to analyze this data.\n",
    "Make sure that you have at least 1000 rows per channel.\n",
    "Print the number of rows in the data frame and display the first few rows of the data frame using head()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d877989-2a9d-41d0-aa29-4d34f2d5e22e",
   "metadata": {},
   "source": [
    "#### Now, I have 2 lists of dictionaries generated by function \"search_keyword_videos\" and function \"extract_30_comments\", I will turn both of them into pandas dataframes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b8441027-42fc-4742-acb8-84fd69c09626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video info dataframe\n",
    "cnn_video_df = pd.DataFrame(cnn_keyword_videoids)\n",
    "fox_video_df = pd.DataFrame(foxnews_keyword_videoids)\n",
    "\n",
    "# Comments info dataframe\n",
    "cnn_comment_df = pd.DataFrame(cnn_videos_comments)\n",
    "fox_comment_df = pd.DataFrame(fox_videos_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c3753e0c-0fb1-408c-947c-652573e19f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes for cnn and fox by \"Video ID\"\n",
    "cnn_df = pd.merge(cnn_comment_df,cnn_video_df, on = 'Video ID', how = 'left' )\n",
    "fox_df = pd.merge(fox_comment_df,fox_video_df, on = 'Video ID', how = 'left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "85f32d68-a02b-4b6c-9b32-9cd54fce857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Comment id', 'Comment title', 'Comment creation time',\n",
       "       'Comment number of likes', 'Comment content', 'Replies', 'Channel Name',\n",
       "       'Video title', 'Video creation time', 'Video number of views'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ebad0eb6-8b19-43af-89a4-59630d30ef44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Comment id', 'Comment title', 'Comment creation time',\n",
       "       'Comment number of likes', 'Comment content', 'Replies', 'Channel Name',\n",
       "       'Video title', 'Video creation time', 'Video number of views'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "52d08c49-d58b-4a73-8281-02c3ebdc5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking the two on top of each other\n",
    "yt_comments = pd.concat([cnn_df,fox_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d6e18d24-2235-42d6-909c-bdef759f459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video ID</th>\n",
       "      <th>Comment id</th>\n",
       "      <th>Comment title</th>\n",
       "      <th>Comment creation time</th>\n",
       "      <th>Comment number of likes</th>\n",
       "      <th>Comment content</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Video title</th>\n",
       "      <th>Video creation time</th>\n",
       "      <th>Video number of views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zH9m20-wq2M</td>\n",
       "      <td>UgzqyxD7DCUCNWkRPLZ4AaABAg</td>\n",
       "      <td>This is so accurate 😂😂😂</td>\n",
       "      <td>2024-01-29T20:04:44Z</td>\n",
       "      <td>0</td>\n",
       "      <td>This is so accurate 😂😂😂</td>\n",
       "      <td>None</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Every Cable News Debate #funny #skit #democrat...</td>\n",
       "      <td>2024-01-29T19:27:30Z</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zH9m20-wq2M</td>\n",
       "      <td>UgxQSXilM5XR909hPXx4AaABAg</td>\n",
       "      <td>Walmart Tom Brady on the weather 🎉🎉</td>\n",
       "      <td>2024-01-29T19:50:36Z</td>\n",
       "      <td>0</td>\n",
       "      <td>Walmart Tom Brady on the weather 🎉🎉</td>\n",
       "      <td>None</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Every Cable News Debate #funny #skit #democrat...</td>\n",
       "      <td>2024-01-29T19:27:30Z</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zH9m20-wq2M</td>\n",
       "      <td>UgzScU1Hdo0wmF1A6bp4AaABAg</td>\n",
       "      <td>projecting much????</td>\n",
       "      <td>2024-01-29T19:48:46Z</td>\n",
       "      <td>0</td>\n",
       "      <td>projecting much????</td>\n",
       "      <td>None</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Every Cable News Debate #funny #skit #democrat...</td>\n",
       "      <td>2024-01-29T19:27:30Z</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zH9m20-wq2M</td>\n",
       "      <td>UgxQi2FRO3a6IukfvL94AaABAg</td>\n",
       "      <td>What county do you live in where the mainstrea...</td>\n",
       "      <td>2024-01-29T19:44:59Z</td>\n",
       "      <td>0</td>\n",
       "      <td>What county do you live in where the mainstrea...</td>\n",
       "      <td>None</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Every Cable News Debate #funny #skit #democrat...</td>\n",
       "      <td>2024-01-29T19:27:30Z</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sdYmRp2K19g</td>\n",
       "      <td>UgyM3XPpNXRFrbezgWl4AaABAg</td>\n",
       "      <td>How can Trump tank the border Bill ? He not th...</td>\n",
       "      <td>2024-01-29T20:15:33Z</td>\n",
       "      <td>0</td>\n",
       "      <td>How can Trump tank the border Bill ? He not th...</td>\n",
       "      <td>None</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Sen. Warren weighs in on Trump&amp;#39;s desire to...</td>\n",
       "      <td>2024-01-29T18:38:34Z</td>\n",
       "      <td>26371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Video ID                  Comment id  \\\n",
       "0  zH9m20-wq2M  UgzqyxD7DCUCNWkRPLZ4AaABAg   \n",
       "1  zH9m20-wq2M  UgxQSXilM5XR909hPXx4AaABAg   \n",
       "2  zH9m20-wq2M  UgzScU1Hdo0wmF1A6bp4AaABAg   \n",
       "3  zH9m20-wq2M  UgxQi2FRO3a6IukfvL94AaABAg   \n",
       "4  sdYmRp2K19g  UgyM3XPpNXRFrbezgWl4AaABAg   \n",
       "\n",
       "                                       Comment title Comment creation time  \\\n",
       "0                            This is so accurate 😂😂😂  2024-01-29T20:04:44Z   \n",
       "1                Walmart Tom Brady on the weather 🎉🎉  2024-01-29T19:50:36Z   \n",
       "2                                projecting much????  2024-01-29T19:48:46Z   \n",
       "3  What county do you live in where the mainstrea...  2024-01-29T19:44:59Z   \n",
       "4  How can Trump tank the border Bill ? He not th...  2024-01-29T20:15:33Z   \n",
       "\n",
       "   Comment number of likes                                    Comment content  \\\n",
       "0                        0                            This is so accurate 😂😂😂   \n",
       "1                        0                Walmart Tom Brady on the weather 🎉🎉   \n",
       "2                        0                                projecting much????   \n",
       "3                        0  What county do you live in where the mainstrea...   \n",
       "4                        0  How can Trump tank the border Bill ? He not th...   \n",
       "\n",
       "  Replies Channel Name                                        Video title  \\\n",
       "0    None          CNN  Every Cable News Debate #funny #skit #democrat...   \n",
       "1    None          CNN  Every Cable News Debate #funny #skit #democrat...   \n",
       "2    None          CNN  Every Cable News Debate #funny #skit #democrat...   \n",
       "3    None          CNN  Every Cable News Debate #funny #skit #democrat...   \n",
       "4    None          CNN  Sen. Warren weighs in on Trump&#39;s desire to...   \n",
       "\n",
       "    Video creation time Video number of views  \n",
       "0  2024-01-29T19:27:30Z                    16  \n",
       "1  2024-01-29T19:27:30Z                    16  \n",
       "2  2024-01-29T19:27:30Z                    16  \n",
       "3  2024-01-29T19:27:30Z                    16  \n",
       "4  2024-01-29T18:38:34Z                 26371  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9865bd-1cf5-472d-9a16-38af9517ca1a",
   "metadata": {},
   "source": [
    "#### 2d (2 pt): Write code to turn the data frame into a CSV and save it in a file called “yt_comments.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b281230a-883e-4118-b3af-592a51f0d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_comments.to_csv('yt_comments.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bed5d-e884-4f49-b3cf-d5eaeba73c69",
   "metadata": {},
   "source": [
    "### Q3) Blue Sky data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae4824-6c18-4bd5-b393-de9526601e28",
   "metadata": {},
   "source": [
    "### 3a (15 pts) For each of the two Blue Sky accounts (The Washington Post and the New York Times) use the Blue Sky API to fetch all posts posted by each account. Go over all posts and check whether the posts’ text contains the election-related keywords you select in Q1. Save relevant information about the posts that are about the election. If you are not able to identify at least 50 posts per account, try expanding your list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "86a27b5f-a0c4-4c25-838d-f2fdee0414f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install atproto --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "06e64967-101c-404b-89e6-d724f5c54eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from atproto import Client, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "97fa706c-267f-48ef-8339-03781f5e7670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProfileViewDetailed(did='did:plc:yfftm3wglvnerwrp5z7qpnwn', handle='tomatofriedegghl.bsky.social', avatar=None, banner=None, description=None, display_name='Louise Lu', followers_count=6, follows_count=10, indexed_at='2024-01-10T01:17:53.077Z', labels=[], posts_count=3, viewer=ViewerState(blocked_by=False, blocking=None, blocking_by_list=None, followed_by=None, following=None, muted=False, muted_by_list=None, py_type='app.bsky.actor.defs#viewerState'), py_type='app.bsky.actor.defs#profileViewDetailed')"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USERNAME = \"tomatofriedegghl.bsky.social\"\n",
    "APP_PASSWORD = \"bisb-bkdh-6avc-tlbl\"\n",
    "client = Client()\n",
    "client.login(USERNAME, APP_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7ef8ddab-5263-4604-bf29-c026c64c6714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed_data_washingtonpost = client.get_author_feed(actor = 'washingtonpost.com')\n",
    "# feed_data_nytimes = client.get_author_feed(actor = 'nytimes.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "52f2889f-d153-4291-8615-0eda4d70621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_posts(client, user, max_posts):\n",
    "    all_post = []\n",
    "    cursor = None\n",
    "    stemmed_keywords = set(porter.stem(keyword) for keyword in keyword_list)\n",
    "    \n",
    "    while len(all_post) < max_posts:\n",
    "        feed_data = client.get_author_feed(user, cursor=cursor)\n",
    "        \n",
    "        if feed_data is not None:\n",
    "            for i, post in enumerate(feed_data.feed):\n",
    "                post_text = feed_data.feed[i].post.record.text.lower()\n",
    "                if any(re.search(r'\\b{}\\b'.format(re.escape(porter.stem(keyword))), post_text) for keyword in stemmed_keywords):\n",
    "                    post = {\n",
    "                        'Account name': user,\n",
    "                        'Post ID uri':feed_data.feed[i].post['uri'],\n",
    "                        'Poster handle': feed_data.feed[i].post.author.handle,\n",
    "                        'Post created_at': feed_data.feed[i].post.record.created_at,\n",
    "                        'Post text':feed_data.feed[i].post.record.text,\n",
    "                        'Post like_count': feed_data.feed[i].post['like_count'],\n",
    "                        'Post reply_count': feed_data.feed[i].post['reply_count'],\n",
    "                        'Post repost_count': feed_data.feed[i].post['repost_count']\n",
    "                    }\n",
    "                    all_post.append(post)\n",
    "                if len(all_post) >= max_posts:\n",
    "                    break\n",
    "            cursor = feed_data.cursor\n",
    "            if cursor is None:\n",
    "                break\n",
    "        else:\n",
    "            print(\"No more data available.\")\n",
    "            break\n",
    "            \n",
    "    return all_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "afbd8b7d-a784-4760-9ea8-249f3bc20923",
   "metadata": {},
   "outputs": [],
   "source": [
    "washingtonpost_results = get_user_posts(client, 'washingtonpost.com', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4e84e3aa-002c-40c7-a537-64725cb68dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_result = get_user_posts(client, 'nytimes.com', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ee9d459b-1d7e-4284-a894-a40b6c4e528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri_list_washington = [d['Post ID uri'] for d in washingtonpost_results if 'Post ID uri' in d]\n",
    "uri_list_nytimes = [d['Post ID uri'] for d in nytimes_result if 'Post ID uri' in d]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1f021-6e31-4a70-9d44-3654aa658889",
   "metadata": {},
   "source": [
    "#### 3b (15 pts): For each of the election-related posts you identified, collect all of their replies. This should include not just the direct replies, but replies of the replies, and so on; i.e., the complete conversation prompted by the post. Make sure that you have at least 1000 comments per account across all posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e3bd4fd8-cd1a-4f3c-96ef-a11d6ae0d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_replies(uri_list):\n",
    "    \n",
    "    all_comments_replies = []\n",
    "    for uri in uri_list:\n",
    "        all_data = client.get_post_thread(uri)\n",
    "        queue = []\n",
    "        queue += all_data.thread.replies\n",
    "        \n",
    "        while queue: # while queue is not empty\n",
    "            reply = queue.pop() # get the reply at the end of the queue\n",
    "            result = {\n",
    "                'Post ID uri':uri,\n",
    "                \"Reply ID URI\": reply.post.uri,\n",
    "                \"Reply poster handle\": reply.post.author.handle,\n",
    "                \"Reply created at\": reply.post.record.created_at,\n",
    "                \"Reply text\": reply.post.record.text,\n",
    "                \"Reply like_count\": reply.post.like_count,\n",
    "                \"Reply reply_count\": reply.post.reply_count,\n",
    "                \"Reply repost count\": reply.post.repost_count\n",
    "            }\n",
    "            all_comments_replies.append(result)\n",
    "            # loop through all replies of this reply (if any) and add them to the queue\n",
    "            if reply.replies is not None:\n",
    "                for sub_reply in reply.replies:\n",
    "                    queue.append(sub_reply)\n",
    "    \n",
    "    return all_comments_replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "57c53161-5ac5-4fa1-ba6d-b20d20efb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "washingtonpost_comments_replies = get_post_replies(uri_list_washington)\n",
    "nytimes_comments_replies = get_post_replies(uri_list_nytimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df369155-725c-4ac3-bd94-fc356c2f3ef2",
   "metadata": {},
   "source": [
    "#### 3c (8 pts): Create a Pandas data frame that contains the relevant information about the data you extracted. Each row of your data frame should represent one reply. It should, at least, include the following columns (you can name the columns as you like):\n",
    "- Account name (Washington Post / New York Times)\n",
    "- Post id\n",
    "- Post text\n",
    "- Post creation time\n",
    "- Post number of likes\n",
    "- Post number of retweets\n",
    "- Reply id\n",
    "- Reply text\n",
    "- Reply creation time\n",
    "- Reply number of likes\n",
    "- Reply number of retweets\n",
    "Include any other information that you think might be relevant for further analyses.\n",
    "Print the number of rows in the data frame and display the first few rows of the data frame using head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "fd2a067f-5699-49e8-b789-af50ae0e2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "washingtonpost_replies_df = pd.DataFrame(washingtonpost_comments_replies)\n",
    "nytimes_replies_df = pd.DataFrame(nytimes_comments_replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "53dede6f-5a57-42a2-a4d0-2d98145ab95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "washingtonpost_posts = pd.DataFrame(washingtonpost_results)\n",
    "nytimes_posts = pd.DataFrame(nytimes_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "86bcddd6-2fa0-4580-ac33-0a423cad8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_all = pd.merge(nytimes_replies_df, nytimes_posts, on = 'Post ID uri', how = 'left')\n",
    "washingtonpost_all = pd.merge(washingtonpost_replies_df, washingtonpost_posts, on = 'Post ID uri', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "0134cca7-55a7-438f-b6f3-07d4f3c70720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID uri</th>\n",
       "      <th>Reply ID URI</th>\n",
       "      <th>Reply poster handle</th>\n",
       "      <th>Reply created at</th>\n",
       "      <th>Reply text</th>\n",
       "      <th>Reply like_count</th>\n",
       "      <th>Reply reply_count</th>\n",
       "      <th>Reply repost count</th>\n",
       "      <th>Account name</th>\n",
       "      <th>Poster handle</th>\n",
       "      <th>Post created_at</th>\n",
       "      <th>Post text</th>\n",
       "      <th>Post like_count</th>\n",
       "      <th>Post reply_count</th>\n",
       "      <th>Post repost_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...</td>\n",
       "      <td>at://did:plc:qo55faqv63ih6uxshusn3mke/app.bsky...</td>\n",
       "      <td>helmutscholz.bsky.social</td>\n",
       "      <td>2024-01-29T18:31:48.044Z</td>\n",
       "      <td>China's real estate/banking sector looks like ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>2024-01-29T18:24:43.450Z</td>\n",
       "      <td>China Evergrande, a massive property company w...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...</td>\n",
       "      <td>at://did:plc:cntyk4pi5cudb7xo4ezlqdoh/app.bsky...</td>\n",
       "      <td>motown.bsky.social</td>\n",
       "      <td>2024-01-28T21:50:55.049Z</td>\n",
       "      <td>There are no conservative voters.\\n\\nThere's M...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>2024-01-28T21:44:00.506Z</td>\n",
       "      <td>Nikki Haley is trying to find a way to diminis...</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...</td>\n",
       "      <td>at://did:plc:p3edo3eknwague2vsigx5dk3/app.bsky...</td>\n",
       "      <td>cinemastrikesback.bsky.social</td>\n",
       "      <td>2024-01-28T21:59:52.952Z</td>\n",
       "      <td>Man, I know plenty of never Trump moderate con...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>2024-01-28T21:44:00.506Z</td>\n",
       "      <td>Nikki Haley is trying to find a way to diminis...</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...</td>\n",
       "      <td>at://did:plc:cntyk4pi5cudb7xo4ezlqdoh/app.bsky...</td>\n",
       "      <td>motown.bsky.social</td>\n",
       "      <td>2024-01-28T22:04:13.346Z</td>\n",
       "      <td>Exactly, that's the \"everyone else\" part.</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>2024-01-28T21:44:00.506Z</td>\n",
       "      <td>Nikki Haley is trying to find a way to diminis...</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...</td>\n",
       "      <td>at://did:plc:p3edo3eknwague2vsigx5dk3/app.bsky...</td>\n",
       "      <td>cinemastrikesback.bsky.social</td>\n",
       "      <td>2024-01-28T22:23:28.400Z</td>\n",
       "      <td>Ah misunderstood you</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>2024-01-28T21:44:00.506Z</td>\n",
       "      <td>Nikki Haley is trying to find a way to diminis...</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Post ID uri  \\\n",
       "0  at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...   \n",
       "1  at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...   \n",
       "2  at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...   \n",
       "3  at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...   \n",
       "4  at://did:plc:eclio37ymobqex2ncko63h4r/app.bsky...   \n",
       "\n",
       "                                        Reply ID URI  \\\n",
       "0  at://did:plc:qo55faqv63ih6uxshusn3mke/app.bsky...   \n",
       "1  at://did:plc:cntyk4pi5cudb7xo4ezlqdoh/app.bsky...   \n",
       "2  at://did:plc:p3edo3eknwague2vsigx5dk3/app.bsky...   \n",
       "3  at://did:plc:cntyk4pi5cudb7xo4ezlqdoh/app.bsky...   \n",
       "4  at://did:plc:p3edo3eknwague2vsigx5dk3/app.bsky...   \n",
       "\n",
       "             Reply poster handle          Reply created at  \\\n",
       "0       helmutscholz.bsky.social  2024-01-29T18:31:48.044Z   \n",
       "1             motown.bsky.social  2024-01-28T21:50:55.049Z   \n",
       "2  cinemastrikesback.bsky.social  2024-01-28T21:59:52.952Z   \n",
       "3             motown.bsky.social  2024-01-28T22:04:13.346Z   \n",
       "4  cinemastrikesback.bsky.social  2024-01-28T22:23:28.400Z   \n",
       "\n",
       "                                          Reply text  Reply like_count  \\\n",
       "0  China's real estate/banking sector looks like ...                 0   \n",
       "1  There are no conservative voters.\\n\\nThere's M...                 8   \n",
       "2  Man, I know plenty of never Trump moderate con...                 1   \n",
       "3          Exactly, that's the \"everyone else\" part.                 3   \n",
       "4                               Ah misunderstood you                 1   \n",
       "\n",
       "   Reply reply_count  Reply repost count Account name Poster handle  \\\n",
       "0                  0                   0  nytimes.com   nytimes.com   \n",
       "1                  1                   1  nytimes.com   nytimes.com   \n",
       "2                  2                   0  nytimes.com   nytimes.com   \n",
       "3                  1                   0  nytimes.com   nytimes.com   \n",
       "4                  0                   0  nytimes.com   nytimes.com   \n",
       "\n",
       "            Post created_at  \\\n",
       "0  2024-01-29T18:24:43.450Z   \n",
       "1  2024-01-28T21:44:00.506Z   \n",
       "2  2024-01-28T21:44:00.506Z   \n",
       "3  2024-01-28T21:44:00.506Z   \n",
       "4  2024-01-28T21:44:00.506Z   \n",
       "\n",
       "                                           Post text  Post like_count  \\\n",
       "0  China Evergrande, a massive property company w...               19   \n",
       "1  Nikki Haley is trying to find a way to diminis...               47   \n",
       "2  Nikki Haley is trying to find a way to diminis...               47   \n",
       "3  Nikki Haley is trying to find a way to diminis...               47   \n",
       "4  Nikki Haley is trying to find a way to diminis...               47   \n",
       "\n",
       "   Post reply_count  Post repost_count  \n",
       "0                 1                  9  \n",
       "1                12                  7  \n",
       "2                12                  7  \n",
       "3                12                  7  \n",
       "4                12                  7  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytimes_washingtonpost = pd.concat([nytimes_all,washingtonpost_all])\n",
    "nytimes_washingtonpost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b9247-f7aa-4b3d-b77d-c7d6026308ee",
   "metadata": {},
   "source": [
    "#### 3d (2 pt): Write code to turn the data frame into a CSV and save it in a file called “bsky_replies.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c61e32d4-7690-43f6-a443-06d6b1cbd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "nytimes_washingtonpost.to_csv('bsky_replies.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
