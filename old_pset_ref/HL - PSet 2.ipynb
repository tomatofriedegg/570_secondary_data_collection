{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d4138e-f292-4736-9f54-a59e8a8ba558",
   "metadata": {},
   "source": [
    "# Hongfan Lu - PSet 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ba275-b83c-4540-870f-3d988e97882a",
   "metadata": {},
   "source": [
    "#### Q1) Asking Questions：\n",
    "\n",
    "What are some compelling questions that you can ask with the dataset you collected?\n",
    "List at least two questions. Enter your responses and the rationale behind choosing those questions in markdown cells. Write your questions and explain your reasoning for each of them.\n",
    "\n",
    "HINT: In the first assignment you had chosen certain keywords to filter data related to the election and had provided a rationale behind the choice of the keywords. This can help you think of potential questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e733f-5f3f-4844-8787-8321fcaf4fe2",
   "metadata": {},
   "source": [
    "**Proposed Question 1**:\n",
    "\n",
    "    Trade War with China (2018-2020) was one of the signature of Trump's presidency. I would like to investigate how did Trump formulate, communicate and insitgated his supporter's recognition on this policy. \n",
    "    Was he using accusation of lying, deception and so forth? I will leverage keywords to find them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53396b2-bccb-4ada-90d0-2f26a4996fb5",
   "metadata": {},
   "source": [
    "**Proposed Question 2**:\n",
    "\n",
    "    Is Trump's tweets angry? My assumption is yes since he was the target of several impeachment? What else emotions does it contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3ef95-651a-4806-9d1d-15e448f5ee0e",
   "metadata": {},
   "source": [
    "#### Q2) Inspect & Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b96d39d-324a-40ae-801d-cd7a1a9a400c",
   "metadata": {},
   "source": [
    "#### 2a) Inspect:  \n",
    "\n",
    "Write code to inspect the data. What do you observe? Along with the code, write your observations in the markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ebf5b54-c005-4bcc-935d-ee34cac28cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cad29d-45bc-49de-b9f3-f2c2d300e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18467, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump = pd.read_csv('psets-trump-20200530.csv')\n",
    "trump.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266910e8-5c71-45a3-8140-ccd69304683e",
   "metadata": {},
   "source": [
    "Each row contains one tweet (or reply) made by Trump. There are the source, acutual tweet content, created timestamp, retweet/favorite count and finally id for that specific tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dcf746-3d81-49c6-a5cb-2a1c204fef93",
   "metadata": {},
   "source": [
    "created_at contains string which needs to be coverted to datetime below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a5a8b5-8df6-4fc0-a93d-2e6eab886615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "Twitter for iPhone      17843\n",
       "Twitter Media Studio      174\n",
       "Twitter for Android       174\n",
       "Media Studio              153\n",
       "Twitter Web Client         48\n",
       "Twitter for iPad           38\n",
       "Twitter Ads                33\n",
       "Twitter Web App             4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d605bd-5272-4d24-9575-75efb35d78de",
   "metadata": {},
   "source": [
    "Most tweets are made through Trump's phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a22b61b-ada2-4629-ac3c-af232c423a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_retweet\n",
       "False    16509\n",
       "True      1900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump['is_retweet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103ed58-2082-4968-9e20-5f3cf9611145",
   "metadata": {},
   "source": [
    "Most tweets of Trump are retweeted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f830ef-c0cc-484b-8793-d4ff9e50a915",
   "metadata": {},
   "source": [
    "- By visually checking the dataset: I found row 93 column 'text' contains uncleaned information. I need to extract the information and put them in the right column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b33a9c6-ccc2-4b7b-a944-647386f90b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is arguably the greatest president in our history.” Thank you @LouDobbs! https://t.co/6dfy0yxu9l,05-27-2020 22:58:18,18223,71416,false,1265779391646187520\\nTwitter for iPhone,At my request the FBI and the Department of Justice are already well into an investigation as to the very sad and tragic death in Minnesota of George Floyd....,05-27-2020 22:39:56,50111,247307,false,1265774767493148672\\nTwitter for iPhone,....I have asked for this investigation to be expedited and greatly appreciate all of the work done by local law enforcement. My heart goes out to George’s family and friends. Justice will be served!,05-27-2020 22:39:56,27476,141521,false,1265774770877902848\\nTwitter for iPhone,If the '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blub_string = trump['text'][93]\n",
    "blub_string[:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a1604-7cde-46bf-9f9c-6e6d3ddd8bef",
   "metadata": {},
   "source": [
    "#### 2b) Clean: \n",
    "\n",
    "Write code to clean the data. Along with the code, you need to write the rationale behind the cleaning process, i.e., what are you observing after the first level of cleaning, what is still messy and needs additional cleaning, how are you deciding to do it, etc. At this stage, your cleaning should at least comprise: (1) common data cleaning steps, and (2) dealing with messy Youtube/Bluesky data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736143e6-3522-4641-b2dc-7a18dd66b95b",
   "metadata": {},
   "source": [
    "- 1. Tackle the blub_string found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84144514-863b-4544-9055-837fc7fb3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = blub_string.split('\\n')\n",
    "original_text = rows[0]\n",
    "other_rows = rows[1:]\n",
    "other_data = [row.split(',') for row in other_rows]\n",
    "trump_cols = list(trump.columns)\n",
    "df = pd.DataFrame(other_data, columns=trump_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609606c5-739f-4327-b3a5-bd11abb372d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_text.split(',')\n",
    "original_data.insert(0,'') # Unknown posting source so insert empty string here. \n",
    "df_row = pd.DataFrame([original_data], columns=trump_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788acb61-47ef-404c-8688-42235d9e998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.concat([df_row, df,trump])\n",
    "trump['text'][93] = '' # delete the information in cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b548f541-57ce-48f7-8b89-7613572909ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18501, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.reset_index(drop=True, inplace=True)\n",
    "trump.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75debf62-2ce5-4eb5-88d9-846207f3e0b6",
   "metadata": {},
   "source": [
    "Adding more rows of information extracted from cell under column 'text' and row 93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc210ed-6fd5-4127-8b2a-79c3c86f86f1",
   "metadata": {},
   "source": [
    "- 2. Transform created_at column to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c744e164-169e-4c08-9e9f-ea292baf347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump['created_at'] = pd.to_datetime(trump['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe199dc-1b6a-49e2-b04e-4143217f92fb",
   "metadata": {},
   "source": [
    "Datetime object will allow us to rank or aggregate the tweets for further comparison and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b46709-7620-4f45-a147-fd68a09c5e90",
   "metadata": {},
   "source": [
    "- 3. Extract potential urls from text; A sepetated column for urls could be useful for analysis; Remove extracted urls from text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca5f2251-7a3b-4a4f-a22c-9aba5bf1c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(text):\n",
    "    urls = re.findall(r'(https?://\\S+)', str(text))\n",
    "    return \",\".join(urls) if urls else None\n",
    "\n",
    "trump['extracted_text_urls'] = trump['text'].apply(extract_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6548ffe2-600c-4a6b-a1d7-05ab9e1d0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLs from text\n",
    "trump['text'] = trump['text'].str.replace(r'http\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae0ebe7-42ce-4296-9717-40e3fcc19939",
   "metadata": {},
   "source": [
    "- 4. Extract RT @ XXX: and make them in a sepetate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d558fddf-b828-433c-a031-62290213e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_RTs(text):\n",
    "    RTs = re.findall(r'^RT @\\w+:', str(text))\n",
    "    return \",\".join(RTs) if RTs else None\n",
    "\n",
    "trump['extracted_RTs'] = trump['text'].apply(extract_RTs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee4bd65e-17f1-4d83-8739-48a595707d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'RT @ XXX:' from text\n",
    "trump['text'] = trump['text'].str.replace(r'^RT @\\w+:', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce9781-ab5b-466e-a59e-8d355db17d72",
   "metadata": {},
   "source": [
    "- 5. Remove any leading or trailing whitespaces in text column, just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b6144e-3670-4d9e-913a-e2de77567f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump['text'] = trump['text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f9ef07-c94a-4ffd-81ce-47afa787b71d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "      <th>extracted_text_urls</th>\n",
       "      <th>extracted_RTs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>He is arguably the greatest president in our history.” Thank you @LouDobbs!</td>\n",
       "      <td>2020-05-27 22:58:18</td>\n",
       "      <td>18223</td>\n",
       "      <td>71416</td>\n",
       "      <td>false</td>\n",
       "      <td>1265779391646187520</td>\n",
       "      <td>https://t.co/6dfy0yxu9l</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>At my request the FBI and the Department of Justice are already well into an investigation as to the very sad and tragic death in Minnesota of George Floyd....</td>\n",
       "      <td>2020-05-27 22:39:56</td>\n",
       "      <td>50111</td>\n",
       "      <td>247307</td>\n",
       "      <td>false</td>\n",
       "      <td>1265774767493148672</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>....I have asked for this investigation to be expedited and greatly appreciate all of the work done by local law enforcement. My heart goes out to George’s family and friends. Justice will be served!</td>\n",
       "      <td>2020-05-27 22:39:56</td>\n",
       "      <td>27476</td>\n",
       "      <td>141521</td>\n",
       "      <td>false</td>\n",
       "      <td>1265774770877902848</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>If the FISA Bill is passed tonight on the House floor I will quickly VETO it. Our Country has just suffered through the greatest political crime in its history. The massive abuse of FISA was a big part of it!</td>\n",
       "      <td>2020-05-27 22:16:31</td>\n",
       "      <td>40598</td>\n",
       "      <td>164483</td>\n",
       "      <td>false</td>\n",
       "      <td>1265768877427851265</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Thank you to @NASA and @SpaceX for their hard work and leadership. Look forward to being back with you on Saturday!</td>\n",
       "      <td>2020-05-27 21:28:24</td>\n",
       "      <td>21816</td>\n",
       "      <td>152454</td>\n",
       "      <td>false</td>\n",
       "      <td>1265756765389418496</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source  \\\n",
       "0                       \n",
       "1  Twitter for iPhone   \n",
       "2  Twitter for iPhone   \n",
       "3  Twitter for iPhone   \n",
       "4  Twitter for iPhone   \n",
       "\n",
       "                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                       He is arguably the greatest president in our history.” Thank you @LouDobbs!   \n",
       "1                                                   At my request the FBI and the Department of Justice are already well into an investigation as to the very sad and tragic death in Minnesota of George Floyd....   \n",
       "2           ....I have asked for this investigation to be expedited and greatly appreciate all of the work done by local law enforcement. My heart goes out to George’s family and friends. Justice will be served!   \n",
       "3  If the FISA Bill is passed tonight on the House floor I will quickly VETO it. Our Country has just suffered through the greatest political crime in its history. The massive abuse of FISA was a big part of it!   \n",
       "4                                                                                               Thank you to @NASA and @SpaceX for their hard work and leadership. Look forward to being back with you on Saturday!   \n",
       "\n",
       "           created_at retweet_count favorite_count is_retweet  \\\n",
       "0 2020-05-27 22:58:18         18223          71416      false   \n",
       "1 2020-05-27 22:39:56         50111         247307      false   \n",
       "2 2020-05-27 22:39:56         27476         141521      false   \n",
       "3 2020-05-27 22:16:31         40598         164483      false   \n",
       "4 2020-05-27 21:28:24         21816         152454      false   \n",
       "\n",
       "                id_str      extracted_text_urls extracted_RTs  \n",
       "0  1265779391646187520  https://t.co/6dfy0yxu9l          None  \n",
       "1  1265774767493148672                     None          None  \n",
       "2  1265774770877902848                     None          None  \n",
       "3  1265768877427851265                     None          None  \n",
       "4  1265756765389418496                     None          None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab0503c7-afe5-4600-95a0-849f363bd8ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trump.to_csv('trump_tweets_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dbbd7-45e1-4469-a4d4-e97d493ec63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f96457-7eb2-4236-a770-de9619aa5e90",
   "metadata": {},
   "source": [
    "#### 2c) Tokenize: \n",
    "\n",
    "Write code to tokenize your entire dataset. Use at least three different types of tokenizers. Display results from all the tokenizers in a pandas dataframe so that you can visually compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64559d1a-2152-432c-bdff-9c3efa3aa8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, casual_tokenize, TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c0d89f-ecdc-4224-95df-5955b5e66240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe for holding the tokenized data later\n",
    "token_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b69467-98fb-4af8-91de-6d242e056ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your tokenizers\n",
    "word_tokenizer = word_tokenize\n",
    "casual_tokenizer = casual_tokenize\n",
    "tweet_tokenizer = TweetTokenizer().tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f549d842-da69-4b09-86b0-ed2a15da11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'text' column using different tokenizers\n",
    "token_df['Word Tokenizer'] = trump['text'].apply(word_tokenizer)\n",
    "token_df['Casual Tokenizer'] = trump['text'].apply(casual_tokenizer)\n",
    "token_df['Tweet Tokenizer'] = trump['text'].apply(tweet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10a2b7b1-9897-4780-befc-dad976d0f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b39924ad-b60d-4ac9-a6ee-33d71ce5e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df['Word Tokenizer'] = token_df['Word Tokenizer'].apply(lambda tokens: remove_stopwords(tokens))\n",
    "token_df['Casual Tokenizer'] = token_df['Casual Tokenizer'].apply(lambda tokens: remove_stopwords(tokens))\n",
    "token_df['Tweet Tokenizer'] = token_df['Tweet Tokenizer'].apply(lambda tokens: remove_stopwords(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6fbd5b0-479e-40d1-804a-915025bba0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to wrap text\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa72a3b0-f1fa-4835-9739-1dac1fc7a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Tokenizer</th>\n",
       "      <th>Casual Tokenizer</th>\n",
       "      <th>Tweet Tokenizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[arguably, greatest, president, history., ”, Thank, @, LouDobbs, !]</td>\n",
       "      <td>[arguably, greatest, president, history, ., ”, Thank, @LouDobbs, !]</td>\n",
       "      <td>[arguably, greatest, president, history, ., ”, Thank, @LouDobbs, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ....]</td>\n",
       "      <td>[request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ...]</td>\n",
       "      <td>[request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[...., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]</td>\n",
       "      <td>[..., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]</td>\n",
       "      <td>[..., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]</td>\n",
       "      <td>[FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]</td>\n",
       "      <td>[FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Thank, @, NASA, @, SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]</td>\n",
       "      <td>[Thank, @NASA, @SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]</td>\n",
       "      <td>[Thank, @NASA, @SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         Word Tokenizer  \\\n",
       "0                                                                                                   [arguably, greatest, president, history., ”, Thank, @, LouDobbs, !]   \n",
       "1                                                 [request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ....]   \n",
       "2  [...., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]   \n",
       "3          [FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]   \n",
       "4                                                                              [Thank, @, NASA, @, SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]   \n",
       "\n",
       "                                                                                                                                                      Casual Tokenizer  \\\n",
       "0                                                                                                  [arguably, greatest, president, history, ., ”, Thank, @LouDobbs, !]   \n",
       "1                                                 [request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ...]   \n",
       "2  [..., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]   \n",
       "3         [FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]   \n",
       "4                                                                                 [Thank, @NASA, @SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]   \n",
       "\n",
       "                                                                                                                                                       Tweet Tokenizer  \n",
       "0                                                                                                  [arguably, greatest, president, history, ., ”, Thank, @LouDobbs, !]  \n",
       "1                                                 [request, FBI, Department, Justice, already, well, investigation, sad, tragic, death, Minnesota, George, Floyd, ...]  \n",
       "2  [..., asked, investigation, expedited, greatly, appreciate, work, done, local, law, enforcement, ., heart, goes, George, ’, family, friends, ., Justice, served, !]  \n",
       "3         [FISA, Bill, passed, tonight, House, floor, quickly, VETO, ., Country, suffered, greatest, political, crime, history, ., massive, abuse, FISA, big, part, !]  \n",
       "4                                                                                 [Thank, @NASA, @SpaceX, hard, work, leadership, ., Look, forward, back, Saturday, !]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f76de-1c6c-4ee6-9325-0dd4f4636812",
   "metadata": {},
   "source": [
    "#### 2d) Pick the best tokenizer. \n",
    "\n",
    "Which one do you think works best for your data and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786ad28-397b-4116-acb6-ee74364447e1",
   "metadata": {},
   "source": [
    " Answer: I will pick the TweetTokenizer, since it interpret the emojis and \"@XXX\" better; Although the difference between casual_tokenizer and tweet_tokenizer is barely recognizable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6234d-1649-40cc-b869-60bbea760f90",
   "metadata": {},
   "source": [
    "#### Q3) Analyze Data for Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a86bb7-d752-4fba-8362-bfbd0b097a9f",
   "metadata": {},
   "source": [
    "#### 3a) Sentiment analysis: \n",
    "\n",
    "Pick at least three different ways of conducting sentiment analysis. Write code to loop through your data and find sentiment for each comment, using each of these methods. Report your observations: What do you observe? Are there any similarities or differences across the methods? In the next question, we will quantify these comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4867dd1b-2d9a-48be-8e29-c30886038e63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvaderSentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvaderSentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m opinion_lexicon\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b845fd2-bc57-44ed-8e9e-eb5245535670",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = token_df.drop(['Word Tokenizer','Casual Tokenizer'], axis = 1)\n",
    "sentiment_df['original_text'] = trump['text']\n",
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b777ba09-230f-47c5-baf6-f91c3eb139ae",
   "metadata": {},
   "source": [
    "- TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c09d05-3c98-4a18-84c6-add5d3e9cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment using TextBlob\n",
    "def textblob_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534bcfa7-b51b-40f7-8c28-e1b1acd6cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['TextBlob_Sentiment'] = sentiment_df['original_text'].apply(textblob_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e2473-a90d-45aa-aa08-a2e73f3c0717",
   "metadata": {},
   "source": [
    "- VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78098bdd-ad0d-4b61-849b-01059a52f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_df['VADER_Sentiment'] = sentiment_df['original_text'].apply(analyzer.polarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1e9f8-b956-4a28-8cab-2d5703831f25",
   "metadata": {},
   "source": [
    "- Opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b0230-f845-4416-9ffa-dd3db9e9031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_sentiment(text):\n",
    "    positive_lexicon = set(opinion_lexicon.positive())\n",
    "    negative_lexicon = set(opinion_lexicon.negative())\n",
    "    \n",
    "    tokens = text.lower().split()\n",
    "    positive_count = sum(word in positive_lexicon for word in tokens)\n",
    "    negative_count = sum(word in negative_lexicon for word in tokens)\n",
    "    \n",
    "    return positive_count, negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24d219-5509-460e-bdbc-113ae2f84549",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['Lexicon_Sentiment'] = sentiment_df['original_text'].apply(lexicon_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f72842-13a7-4f5f-9130-3deaa4077dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f14106-4bc1-43ac-8e9f-cd0cf33d93fc",
   "metadata": {},
   "source": [
    "- Although the absolute score is different in value, all three sentiment agrees on whether an emotion is positive or negative.\n",
    "- It take a lot longer to run opinion_Lexicon, compared to the other two methods.\n",
    "- TextBlob Polarity seems to be comparable to the BADER_Sentiment compound methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb51b2-b29e-463b-9574-49f6c3d158c9",
   "metadata": {},
   "source": [
    "#### 3b) Quantitatively comparing methods: \n",
    "\n",
    "Is there a way to do a pairwise comparison of the methods that you picked? You need to report at least one pairwise comparison between the methods. Better if you are able to report all pairwise comparisons across all methods. In your pairwise comparison, compute a quantitative measure to show what proportion of comments match or do not match between two measures. You can also include the rationale behind the choice of your measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f34ce-4690-4caa-a6bb-c7288ed46fc2",
   "metadata": {},
   "source": [
    "- TextBlob\n",
    "    - Creating new column for textblob polarity; Value will be replaced\n",
    "    - Extracting only polarity from TextBlob\n",
    "    - Round the polarity scores to have 1 decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7149b3-5cfd-430f-a740-abd1e13f1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['TextBlob_Sentiment_Polarity'] = sentiment_df['TextBlob_Sentiment']\n",
    "for i in range(0,len(sentiment_df['TextBlob_Sentiment'])):\n",
    "    sentiment_df['TextBlob_Sentiment_Polarity'][i] = sentiment_df['TextBlob_Sentiment'][i].polarity\n",
    "sentiment_df['TextBlob_Sentiment_Polarity'] = pd.to_numeric(sentiment_df['TextBlob_Sentiment_Polarity'])\n",
    "sentiment_df['TextBlob_Sentiment_Polarity'] = sentiment_df['TextBlob_Sentiment_Polarity'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067b000-cfa2-4728-ae9c-0981dde03a9a",
   "metadata": {},
   "source": [
    "- VADER\n",
    "    - Creating new column for VADER Compound;\n",
    "    - Extracting compound from VADER\n",
    "    - Round the compound scores to have 1 decimal point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcaabdd-405f-4716-8467-2264b7813aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['VADER_Sentiment_Compound'] = sentiment_df['VADER_Sentiment']\n",
    "for i in range(0,len(sentiment_df['VADER_Sentiment'])):\n",
    "    sentiment_df['VADER_Sentiment_Compound'][i] = sentiment_df['VADER_Sentiment'][i]['compound']\n",
    "sentiment_df['VADER_Sentiment_Compound'] = pd.to_numeric(sentiment_df['VADER_Sentiment_Compound'], errors='coerce')\n",
    "sentiment_df['VADER_Sentiment_Compound'] = round(sentiment_df['VADER_Sentiment_Compound'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e2740-531a-4145-b26d-44f2b5c8c91c",
   "metadata": {},
   "source": [
    "- Opinion_Lexicon\n",
    "    - Transforming Lexicon_Sentiment; \n",
    "    - give equal weight to positive and negative counts but +0.5 for positive and -0.5 for negative\n",
    "    - Scale the lexicon sentiment column to make them between -1 and 1 like the other two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0810e899-3ac6-42a5-a66d-463a314740fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df['Lexicon_Sentiment_weighted'] = sentiment_df['Lexicon_Sentiment']\n",
    "for i in range(0,len(sentiment_df['Lexicon_Sentiment'])):\n",
    "    sentiment_df['Lexicon_Sentiment_weighted'][i] = sentiment_df['Lexicon_Sentiment'][i][0]*0.5 + sentiment_df['Lexicon_Sentiment'][i][1]*(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb803635-51ee-4bd8-a5c8-41c7e63db76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "sentiment_df['Lexicon_weighted_normalized'] = scaler.fit_transform(sentiment_df[['Lexicon_Sentiment_weighted']])\n",
    "sentiment_df['Lexicon_weighted_normalized'] = round(sentiment_df['Lexicon_weighted_normalized'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a02c4-54d3-4522-9b09-a6697ad7e785",
   "metadata": {},
   "source": [
    "- Pairwise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f5949-6e83-42a0-ae61-76abfddfcceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_VADER_matches = (sentiment_df['TextBlob_Sentiment_Polarity'] == sentiment_df['VADER_Sentiment_Compound']).sum()\n",
    "TB_VADER_percentage_matches = (TB_VADER_matches / len(sentiment_df)) * 100\n",
    "\n",
    "print(f\"Percentage of TextBlob and VADER matching values: {TB_VADER_percentage_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa58cfa-113f-4f70-808d-fae743c94697",
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_Lexicon_matches = (sentiment_df['TextBlob_Sentiment_Polarity'] == sentiment_df['Lexicon_weighted_normalized']).sum()\n",
    "TB_Lexicon_percentage_matches = (TB_Lexicon_matches / len(sentiment_df)) * 100\n",
    "\n",
    "print(f\"Percentage of TextBlob and Lexicon weighted matching values: {TB_Lexicon_percentage_matches:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b161e3-e744-469f-817a-ad165b011f28",
   "metadata": {},
   "source": [
    "#### 3c) Qualitative + Quantitative comparison: \n",
    "\n",
    "Write code to randomly pick 40 comments. By hand, mark each of their sentiments. Now pick two sentiment analysis methods of your choice to automatically find the sentiments of these 40 tweets. Considering your hand labels as the absolute ground truth, write code to determine which sentiment analysis method works better. It might be that both methods you picked do equally well. Provide a rationale for your response in a markdown cell.\n",
    "\n",
    "HINT: The more the analysis method’s output matches with your labels, the better it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97307c61-7607-4552-8d6b-e7173e02cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = trump.sample(n=40, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663573cb-c584-4b96-a070-34137e40b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['hand_label'] = [-0.3, 0.7, 0.3, -0.2, -0.5, -0.7, -0.5, 0.4, -0.5, 0.8, 0.2, -0.2, -0.1,0.6,-0.3,0.8,0.3,-0.5,0.8,0.8,-0.1,-0.2,0.4,-0.3,0.4,-0.1,-0.3,0.7,0.1,0.1,0.3,-0.5,0.5,-0.5,0.7,-0.7,0,0.7,0.8,0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0741d-9233-4760-9bd4-edfe07ab7221",
   "metadata": {},
   "source": [
    "- VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825aa45c-6eaa-46e0-bc49-80d639dec6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['VADER'] = sampled_df['text'].apply(analyzer.polarity_scores)\n",
    "# Set up a new column 'VADER_Compound_2' in sampled_df\n",
    "sampled_df['VADER_Compound'] = sampled_df['VADER']\n",
    "\n",
    "# Extract the 'compound' score from the 'VADER_Compound' dictionary\n",
    "for i in range(0, 40):\n",
    "    sampled_df.at[i, 'VADER_Compound'] = sampled_df['VADER_Compound'][i]['compound']\n",
    "\n",
    "# Convert the 'VADER_Compound_2' column to numeric, rounding to 1 decimal point\n",
    "sampled_df['VADER_Compound'] = pd.to_numeric(sampled_df['VADER_Compound'], errors='coerce').round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346d2c76-c98c-477f-b895-b8cf4da6b1c0",
   "metadata": {},
   "source": [
    "- TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe8425-37d5-4e37-95d8-a1c2308bc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['TextBlob'] = sampled_df['text'].apply(textblob_sentiment)\n",
    "# # Set up a new column 'VADER_Compound_2' in sampled_df\n",
    "sampled_df['TextBlob_Polarity'] = sampled_df['TextBlob']\n",
    "for i in range(0,40):\n",
    "    sampled_df['TextBlob_Polarity'][i] = sampled_df['TextBlob'][i].polarity\n",
    "sampled_df['TextBlob_Polarity'] = pd.to_numeric(sampled_df['TextBlob_Polarity']).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c6def-771c-4948-982f-7322003c7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = sampled_df[['hand_label', 'VADER_Compound', 'TextBlob_Polarity']]\n",
    "# Calculate absolute differences\n",
    "comparison['VADER/Label'] = abs(comparison['hand_label'] - comparison['VADER_Compound'])\n",
    "comparison['TextBlob/Label'] = abs(comparison['hand_label'] - comparison['TextBlob_Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edced8e-33d9-4c88-9115-a756eed6344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vader_average = comparison['VADER/Label'].mean()\n",
    "print(\"Average Difference between Vader compound and my hand label is: \", Vader_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c2896-20e0-465b-bbfb-2d9f064cb98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob_average = comparison['TextBlob/Label'].mean()\n",
    "print(\"Average Difference between TextBlob Polarity and my hand label is: \", TextBlob_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d62336-c686-4054-9f81-99fae4baac56",
   "metadata": {},
   "source": [
    "Since the average abosolute difference is smaler for VADER method, it is better in this test against my hand label;Nevertheless, my hand label are not necessarily the best reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb4f53-c7e8-4e3b-bc58-0da7fb6ad8d1",
   "metadata": {},
   "source": [
    "#### Q4) Analyze Data with LIWC\n",
    "Pick at least three dimensions from LIWC that you would want to investigate on your data. You can find a version of the LIWC dictionary here. Write code to find what proportion of each of the two dimensions you picked are present in your data. Motivate your choice of dimension with a research question. For example, if you are curious to know the prevalence of angry comments, you can pick the “angry” dimension in LIWC. Another neat trick here would be to make your code modular via Python functions so that later you can reuse this function for computing across multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e44fac-2e69-454c-9fe3-ad4176d52f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4692e-cb5f-45f1-a4c5-f68f4f9bfc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = pd.read_csv('LIWC2015 dictionary poster.xlsx - 2015-08-24-LIWC2015 - Poster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe30106-ea52-4dfb-88fd-293e1886e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict = collections.defaultdict(list)\n",
    "\n",
    "for header_name in liwc:\n",
    "    dict_key = \"\".join(filter(lambda x: not x.startswith('Unnamed:'), map(str, header_name))).strip('0123456789\\n ')\n",
    "    liwc_dict[dict_key] += list(filter(lambda x: not pd.isnull(x), liwc[header_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb7a42-36b1-42bb-b3e2-261902e75d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict['Anger'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467daab-6b1d-48f2-a2bc-fb8c4e0cb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58871150-4335-4f28-88f2-1e526b4c05cf",
   "metadata": {},
   "source": [
    "#### I would like to check for 'Anger', 'Negemo', 'Adj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a591db-c221-43a3-a102-143595d2aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = token_df['Tweet Tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d1070-ef5a-43e7-8176-fe96a3adc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_liwc(liwc_key, tweet_tokens):\n",
    "    all_token = []\n",
    "    emotion_keywords = liwc_dict[liwc_key]    \n",
    "    for sentence in tweet_tokens:\n",
    "        degree = 0    \n",
    "        for token in sentence:\n",
    "            if token in emotion_keywords:\n",
    "                degree += 1        \n",
    "        # Append 1 if emotion keyword is detected, otherwise append 0\n",
    "        all_token.append(1 if degree != 0 else 0)\n",
    "    return all_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef81b45-e073-4d74-a88a-d7c567235110",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_percentage = detect_liwc('Anger', tokens)\n",
    "print(f\"The percentage of Anger words is: {sum(anger_percentage)/len(anger_percentage)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a6453-00cd-4d5f-8cc0-db966f5f4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "negemo = anger_percentage = detect_liwc('Negemo', tokens)\n",
    "print(f\"The percentage of Negative Emotion words is: {sum(negemo)/len(negemo)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8807b83-4582-40ed-96de-9463eeb89041",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = anger_percentage = detect_liwc('Adj', tokens)\n",
    "print(f\"The percentage of Adjective words is: {sum(Adj)/len(Adj)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551c9e3-668b-4675-9482-e79803c11efa",
   "metadata": {},
   "source": [
    "#### Q5) Analyze Data over time\n",
    "How does the polarity (sentiment) of your corpus change over time? Answer this question by showing plots. You need to plot polarity for at least two of your three sentiment analyzers chosen earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73b3d9-c8d6-46a1-be36-6630fffade72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4728f-3c06-494b-a385-2a2f7cc89347",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump['Vader_compound'] = sentiment_df['VADER_Sentiment_Compound']\n",
    "trump['TextBlob_Polarity'] = sentiment_df['TextBlob_Sentiment_Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9975c3f-21c2-4e77-9f54-38bcac3a9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_df = trump\n",
    "df_grouped = smooth_df.groupby(smooth_df['created_at'].dt.to_period('M')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79ab8a6-f9f9-4a8c-8146-cec16f4f4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df_grouped.index.to_timestamp(), df_grouped['Vader_compound'], label='Vader Compound', marker='o')\n",
    "plt.plot(df_grouped.index.to_timestamp(), df_grouped['TextBlob_Polarity'], label='TextBlob Polarity', marker='x')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.title('Sentiment Over Time')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687ee47-dd20-454c-b3d0-e134d40c0c41",
   "metadata": {},
   "source": [
    "#### Drawing conclusions from the plots: \n",
    "What do you observe from the plots? Can you draw conclusions from your plots based on how the election campaigns were unfolding in the real world? What else can you infer from the plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816baec-32f6-44ca-9f0e-cd2edee4b85a",
   "metadata": {},
   "source": [
    "- Answer:\n",
    "\n",
    "    An obvious trend of Trump's tweet comments is that the sentiment scores are trending down, expecially towards the 2019-2020 period. During that time, there were cases and impeachments against him so he spent a lot of time tweeting on those matters and thus adopt an negative tones towards many people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
